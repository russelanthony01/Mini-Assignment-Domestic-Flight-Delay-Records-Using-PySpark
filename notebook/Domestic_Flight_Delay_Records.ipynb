{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f7eade2-9197-46c6-9002-bad4bfcf6134",
   "metadata": {},
   "source": [
    "## Domestic Flight Delay Records\n",
    "- **Analysis performed by :-** Russel Anthony Reynold Chandanshiv\n",
    "\n",
    "---\n",
    "\n",
    "- Copyright (c) 2025 Russel Anthony Chandanshiv\n",
    "- Licensed under the MIT License\n",
    "  \n",
    "---\n",
    "\n",
    "### Introduction\r\n",
    "\r\n",
    "The data set ‘Domestic Flight Delay Records’ contains comprehensive data about domestic flights in the United States, such as flight dates, airtime, flight distance, scheduled departure/arrival times and departure and arrival delays.</br>\n",
    "</br>\n",
    "The Data Set contains **`7 Features` and `1,000,000 Observations`**. Each observation recorded in the Data Set represents a single flight.\n",
    "</br>\n",
    "</br> **Features**\n",
    "- **`FL_DATE`** - Flight Date.\n",
    "- **`DEP_DELAY`** - Departure delay (in minutes). `[Negative : Early Departure, Positive : Flight Delay, Zero : In-time]`\n",
    "- **`ARR_DELAY`** - Arrival delay (in minutes). `[Negative : Early Arrival, Positive : Flight Delay, Zero : In-time]`\n",
    "- **`AIR_TIME`** - Total Flight Duration (in Air).\n",
    "- **`DISTANCE`** - Total Flight Distance (in Miles).\n",
    "- **`DEP_TIME`** - Scheduled / Actual Departure Time.\n",
    "- **`ARR_TIME`** - Scheduled / Actual Arrival Time.\n",
    "\n",
    "**Libraries and Dependencies**\n",
    "- PySpark\n",
    "\n",
    "**Assumptions**\n",
    "- `FL_DATE` is in MM/DD/YYY format\n",
    "- `DEP_TIME` and `ARR_TIME` represent 24-hour clock time. HH/MM format.\n",
    "- `DEP_DELAY` and `ARR_DELAY` and `AIR_TIME` measured in Minutes.\n",
    "- `DISTANCE` measured in Miles.\n",
    "- Each record represents one unique flight details.\n",
    "- Negative values in `DEP_DELAY` and `ARR_DELAY` represent Early Departure / Early Arrival. Positive represents delay. Zero represents On-time.\n",
    "\n",
    "**WARNING:** Do not re-run this notebook without installing all required libraries and dependencie\r\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a1831-a47b-44bf-a08a-eab2b0102886",
   "metadata": {},
   "source": [
    "**Note:** The dataset used in this analysis is not publicly shared to ensure compliance with copyright and data ownership regulations. This notebook contains only the analytical workflow, methodologies, and visualizations derived from the dataset. All analysis and conclusions are original and created for educational and research purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42825e21-f655-4600-9cbc-297e70f60394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession is currently Active.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, DateType, FloatType, DoubleType, TimestampType, DateType\n",
    "from pyspark.sql.functions import col, trim, to_date\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Initializing Spark session and Confirming if the Spark Session actually exists.\n",
    "\n",
    "try:\n",
    "    spark = (\n",
    "             SparkSession.builder \n",
    "            .appName(\"DomesticFlightAnalysis\")\n",
    "            .getOrCreate()\n",
    ")\n",
    "except Exception:\n",
    "    print (\"SparkSession is not currently Active. This is due to {Exception}.\")\n",
    "else:\n",
    "    if isinstance(spark, SparkSession) and \"spark\" in locals():\n",
    "        print (\"SparkSession is currently Active.\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59514ed3-35e6-443d-b948-cdd14bbeee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first few rows of the PySpark Domestic Flight DataFrame as follows:\n",
      "\n",
      "+---------+---------+---------+--------+--------+---------+---------+\n",
      "|  FL_DATE|DEP_DELAY|ARR_DELAY|AIR_TIME|DISTANCE| DEP_TIME| ARR_TIME|\n",
      "+---------+---------+---------+--------+--------+---------+---------+\n",
      "| 1/1/2006|        5|       19|     350|    2475| 9.083333|12.483334|\n",
      "| 1/2/2006|      167|      216|     343|    2475|11.783334|15.766666|\n",
      "| 1/3/2006|       -7|       -2|     344|    2475| 8.883333|12.133333|\n",
      "| 1/4/2006|       -5|      -13|     331|    2475| 8.916667|    11.95|\n",
      "| 1/5/2006|       -3|      -17|     321|    2475|     8.95|11.883333|\n",
      "| 1/6/2006|       -4|      -32|     320|    2475| 8.933333|11.633333|\n",
      "| 1/8/2006|       -3|       -2|     346|    2475|     8.95|12.133333|\n",
      "| 1/9/2006|        3|        0|     334|    2475|     9.05|12.166667|\n",
      "|1/10/2006|       -7|      -21|     334|    2475| 8.883333|11.816667|\n",
      "|1/11/2006|        8|      -10|     321|    2475| 9.133333|     12.0|\n",
      "+---------+---------+---------+--------+--------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the Domestic Flight Dataset\n",
    "domestic_flight_df = spark.read.csv (\"Flight Dataset - CSV(in).csv\", inferSchema = True, header = True)\n",
    "\n",
    "# Caching the Dataset for faster computations\n",
    "domestic_flight_df.cache()\n",
    "\n",
    "# Calling an Action after caching (Viewing first 10 Rows)\n",
    "print (\"The first few rows of the PySpark Domestic Flight DataFrame as follows:\\n\")\n",
    "domestic_flight_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edaf02b8-b7bf-443f-8c17-31fc3110ef82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Schema of the PySpark Domestic Flight DataFrame is as follows:\n",
      "\n",
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- DEP_DELAY: integer (nullable = true)\n",
      " |-- ARR_DELAY: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- DEP_TIME: double (nullable = true)\n",
      " |-- ARR_TIME: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the DataFrame\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "print (\"The Schema of the PySpark Domestic Flight DataFrame is as follows:\\n\")\n",
    "domestic_flight_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffde3f03-0e6d-411e-ad15-7a27dcd68e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Schema of the PySpark Domestic Flight DataFrame (after conversion) is as follows:\n",
      "\n",
      "root\n",
      " |-- FL_DATE: date (nullable = true)\n",
      " |-- DEP_DELAY: integer (nullable = true)\n",
      " |-- ARR_DELAY: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- DEP_TIME: double (nullable = true)\n",
      " |-- ARR_TIME: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Converting FL_DATE to suitable Date Format\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "domestic_flight_df = domestic_flight_df.withColumn(\"FL_DATE\", to_date(col(\"FL_DATE\"), \"M/d/yyyy\"))\n",
    "\n",
    "print (\"The Schema of the PySpark Domestic Flight DataFrame (after conversion) is as follows:\\n\")\n",
    "domestic_flight_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0883b229-6da9-4b41-929a-bd98208bd940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of rows in our PySpark DataSet : 1,000,000 Rows / Flights / Observations.\n"
     ]
    }
   ],
   "source": [
    "print (f\"The total number of rows in our PySpark DataSet : {domestic_flight_df.count():,} Rows / Flights / Observations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a57cccf6-c545-4bfb-8b58-ab3970ad5a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total number of rows in our PySpark DataSet (After dropping duplicates) : 999,994 Rows / Flights / Observations.\n"
     ]
    }
   ],
   "source": [
    "# Dropping Duplicates (If any)\n",
    "domestic_flight_df = domestic_flight_df.dropDuplicates()\n",
    "\n",
    "# Caching the Dataset for faster computations\n",
    "domestic_flight_df.cache()\n",
    "\n",
    "# After dropping duplicates (if any)\n",
    "print (f\"The Total number of rows in our PySpark DataSet (After dropping duplicates) : {domestic_flight_df.count():,} Rows / Flights / Observations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48414ea4-a619-4ef2-9a39-23d0b7aee1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|Number of Missing Values|\n",
      "+------------------------+\n",
      "|                       0|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the Total Number of Missing Values in Our Dataset\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Dropping the View if it exists\n",
    "spark.sql(\"DROP VIEW IF EXISTS missing_value_view\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Creating a Temporary View\n",
    "domestic_flight_df.createTempView(\"missing_value_view\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Check for missing values\n",
    "number_of_missing_vals = spark.sql(\"\"\"\n",
    "                                    SELECT COUNT(*) AS `Number of Missing Values`\n",
    "                                    FROM missing_value_view  \n",
    "                                    WHERE \n",
    "                                    FL_DATE IS NULL \n",
    "                                    OR \n",
    "                                    DEP_DELAY IS NULL\n",
    "                                    OR\n",
    "                                    ARR_DELAY IS NULL\n",
    "                                    OR\n",
    "                                    AIR_TIME IS NULL\n",
    "                                    OR\n",
    "                                    DISTANCE IS NULL\n",
    "                                    OR\n",
    "                                    DEP_TIME IS NULL\n",
    "                                    OR\n",
    "                                    ARR_TIME IS NULL                                    \n",
    "\"\"\")\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Let's view the count of missing values\n",
    "number_of_missing_vals.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a3751d-737f-40a7-8049-baf83f5c08fb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d9cff3-dc0b-4714-ae58-80daef006fc4",
   "metadata": {},
   "source": [
    "#### Count Flights Arriving Earlier Than Expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cce63079-cad1-4599-b92e-8bdc6b190b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_arrivals(dataframe):\n",
    "    \"\"\"\n",
    "    Docstring: \n",
    "              Take's a PySpark Dataframe as input.\n",
    "              Checks how many flights arrived earlier than expected.\n",
    "              Return a PySpark Dataframe with the Number of flights which arrived earlier than expected.\n",
    "    Parameters: \n",
    "               Spark DataFrame\n",
    "    Arguments: \n",
    "               Domestic Flights PySpark DataFrame\n",
    "    Returns:\n",
    "               A PySpark Dataframe with the Number of flights which arrived earlier than expected.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a Temporary View for SQL Query\n",
    "    dataframe.createOrReplaceTempView(\"domestic_flight_view\")\n",
    "\n",
    "    sql_query_1 = f\"\"\"\n",
    "                      WITH TOTAL_FLIGHT_CTE AS\n",
    "                      (SELECT\n",
    "                           COUNT (*) AS `TOTAL FLIGHT`\n",
    "                       FROM\n",
    "                         domestic_flight_view),\n",
    "\n",
    "                      EARLY_ARRIVAL_CTE AS\n",
    "                      (SELECT\n",
    "                          COUNT (*) AS `EARLY ARRIVAL`\n",
    "                      FROM\n",
    "                          domestic_flight_view\n",
    "                      WHERE\n",
    "                          ARR_DELAY < 0)\n",
    "\n",
    "                      SELECT\n",
    "                          CONCAT (`EARLY ARRIVAL`, \" Flights\") AS `EARLY ARRIVALS`,\n",
    "                          CONCAT (`TOTAL FLIGHT`, \" Flights\") AS `TOTAL FLIGHTS`,\n",
    "                          CONCAT (ROUND ((`EARLY ARRIVAL` / `TOTAL FLIGHT`) * 100, 2), \" %\") AS `PERCENTAGE OF EARLY ARRIVALS`\n",
    "                      FROM\n",
    "                          TOTAL_FLIGHT_CTE, EARLY_ARRIVAL_CTE\n",
    "                   \"\"\"\n",
    "\n",
    "    return spark.sql(sql_query_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6dbce6d-5387-40ba-a4c5-d1860a933840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Flights that arrived earlier than expected:-\n",
      "\n",
      "+--------------+--------------+----------------------------+\n",
      "|EARLY ARRIVALS| TOTAL FLIGHTS|PERCENTAGE OF EARLY ARRIVALS|\n",
      "+--------------+--------------+----------------------------+\n",
      "|534653 Flights|999994 Flights|                     53.47 %|\n",
      "+--------------+--------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"The Number of Flights that arrived earlier than expected:-\\n\")\n",
    "early_arrivals(domestic_flight_df).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae7883f-f241-4b6f-b69a-fce31c1ac7f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e5fbd-cc7e-42cc-bb84-d35f5cf1d50a",
   "metadata": {},
   "source": [
    "#### Determine Typical Departure Time for Long-Distance Flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d9b204c-2133-4e46-b018-ea78c68750a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def typical_departure_time(dataframe):\n",
    "    \"\"\"\n",
    "    Docstring: \n",
    "               Take's a PySpark Dataframe as input.\n",
    "               Determines the Typical Departure Time for flights over 2000 Miles.\n",
    "               Return a PySpark Dataframe with the Average Departure Time for flights over 2000 Miles.\n",
    "    Parameters: \n",
    "               Spark DataFrame\n",
    "    Arguments: \n",
    "               Domestic Flights PySpark DataFrame\n",
    "    Returns:\n",
    "               A PySpark Dataframe with the Average Departure Time for flights over 2000 Miles.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a Temporary View for SQL Query\n",
    "    dataframe.createOrReplaceTempView(\"domestic_flight_view\")\n",
    "\n",
    "    sql_query_1 = f\"\"\"\n",
    "                      SELECT\n",
    "                          ROUND (AVG(DEP_TIME), 2) AS `TYPICAL DEPARTURE TIME (RAW)`,\n",
    "                          CONCAT (FLOOR (AVG(DEP_TIME)), \" HOUR\") AS `TYPICAL DEPARTURE TIME (HOUR)`,\n",
    "                          CONCAT (ROUND (MOD (AVG(DEP_TIME) * 60, 60), 0), \" MINUTES\") AS `TYPICAL DEPARTURE TIME (MINUTE)`,\n",
    "                          \n",
    "                          CASE WHEN\n",
    "                              FLOOR (AVG(DEP_TIME)) >= 12 THEN \n",
    "                                  CONCAT (FLOOR (AVG(DEP_TIME)), \" PM \", ROUND (MOD (AVG(DEP_TIME) * 60, 60), 0), \" MINUTES\") \n",
    "                              ELSE\n",
    "                                  CONCAT (FLOOR (AVG(DEP_TIME)), \" AM \", ROUND (MOD (AVG(DEP_TIME) * 60, 60), 0), \" MINUTES\")       \n",
    "                          END AS `TYPICAL DEPARTURE TIME`\n",
    "                          \n",
    "                      FROM\n",
    "                          domestic_flight_view  \n",
    "                      WHERE\n",
    "                           DISTANCE > 2000\n",
    "                   \"\"\"\n",
    "    \n",
    "    return spark.sql(sql_query_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70349ed4-43a3-4731-a1ba-2edaf1255980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Typical Departure Time of Flights with over 2000 Miles is as follows:-\n",
      "\n",
      "+----------------------------+-----------------------------+-------------------------------+----------------------+\n",
      "|TYPICAL DEPARTURE TIME (RAW)|TYPICAL DEPARTURE TIME (HOUR)|TYPICAL DEPARTURE TIME (MINUTE)|TYPICAL DEPARTURE TIME|\n",
      "+----------------------------+-----------------------------+-------------------------------+----------------------+\n",
      "|                       13.97|                      13 HOUR|                   58.0 MINUTES|    13 PM 58.0 MINUTES|\n",
      "+----------------------------+-----------------------------+-------------------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"The Typical Departure Time of Flights with over 2000 Miles is as follows:-\\n\")\n",
    "typical_departure_time(domestic_flight_df).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71544c54-2e7b-4bc4-8dc3-748ceccf93a6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c5f23a-ab83-4355-ae11-0fc5ff48c1a1",
   "metadata": {},
   "source": [
    "#### Proportion of Flights with Arrival Delays > 60 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87b72eb3-a89f-4d9a-9313-9b0def1f8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion_of_flights(dataframe):\n",
    "    \"\"\"\n",
    "    Docstring: \n",
    "               Take's a PySpark Dataframe as input.\n",
    "               Flights with Arrival Delay Longer than 60 Minutes / Total Number of Flights * 100\n",
    "               Return a PySpark Dataframe with the proportion of flights that have Arrival Delays longer than 60 Minutes.\n",
    "    Parameters: \n",
    "               Spark DataFrame\n",
    "    Arguments: \n",
    "               Domestic Flights PySpark DataFrame\n",
    "    Returns:\n",
    "               A PySpark Dataframe with the proportion of flights that have Arrival Delays longer than 60 Minutes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a Temporary View for SQL Query\n",
    "    dataframe.createOrReplaceTempView(\"domestic_flight_view\")\n",
    "\n",
    "    sql_query_1 = f\"\"\"\n",
    "                      WITH TOTAL_FLIGHTS_CTE AS\n",
    "                      (SELECT\n",
    "                           COUNT (*) AS TOTAL_FLIGHTS\n",
    "                       FROM\n",
    "                           domestic_flight_view),\n",
    "\n",
    "                      FLIGHT_DELAY_CTE AS\n",
    "                      (SELECT\n",
    "                           COUNT (*) AS FLIGHTS_WITH_DELAY\n",
    "                       FROM\n",
    "                           domestic_flight_view\n",
    "                       WHERE\n",
    "                           ARR_DELAY > 60)\n",
    "\n",
    "                      SELECT\n",
    "                          CONCAT (ROUND((F.FLIGHTS_WITH_DELAY / T.TOTAL_FLIGHTS) * 100, 2), \" %\") AS `PROPORTION OF FLIGHTS WITH DELAY LONGER THAN SIXTY MINUTES`\n",
    "                      FROM\n",
    "                          TOTAL_FLIGHTS_CTE AS T,\n",
    "                          FLIGHT_DELAY_CTE AS F  \n",
    "                   \"\"\"\n",
    "\n",
    "    return spark.sql(sql_query_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c20e860-4354-497b-a7df-f2db9e93a595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Proportion of Flights with Delay longer than 60 minutues : 5.31 %\n",
      "\n",
      "+----------------------------------------------------------+\n",
      "|PROPORTION OF FLIGHTS WITH DELAY LONGER THAN SIXTY MINUTES|\n",
      "+----------------------------------------------------------+\n",
      "|                                                    5.31 %|\n",
      "+----------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"The Proportion of Flights with Delay longer than 60 minutues : {proportion_of_flights(domestic_flight_df).collect()[0][0]}\\n\")\n",
    "proportion_of_flights(domestic_flight_df).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb822f-95f6-40be-843a-f88e9ccaa134",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d7baac-9d87-4541-9bad-55e60cd82f06",
   "metadata": {},
   "source": [
    "#### Average Airtime for Flights Departing Before 9:00 AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e5230e3-1c3d-472d-8b83-0cbb448d724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_air_time(dataframe):\n",
    "    \"\"\"\n",
    "    Docstring: \n",
    "               Take's a PySpark Dataframe as input.\n",
    "               Finds the Average Airtime (in minutes) for flights that left before 9:00AM.\n",
    "               Return a PySpark Dataframe with the Average Airtime (in minutes) for flights that left before 9:00AM.\n",
    "    Parameters: \n",
    "               Spark DataFrame\n",
    "    Arguments: \n",
    "               Domestic Flights PySpark DataFrame\n",
    "    Returns:\n",
    "               A PySpark Dataframe with the Average Airtime for flights that left before 9:00AM.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a Temporary View for SQL Query\n",
    "    dataframe.createOrReplaceTempView(\"domestic_flight_view\")\n",
    "\n",
    "    sql_query_1 = f\"\"\"\n",
    "                      WITH AVERAGE_AIRTIME_CTE  \n",
    "                      (SELECT\n",
    "                          ROUND (AVG(AIR_TIME), 2) AS `AVERAGE AIR TIME (IN RAW MINUTES)`\n",
    "                      FROM\n",
    "                          domestic_flight_view\n",
    "                      WHERE\n",
    "                          DEP_TIME < 9)\n",
    "\n",
    "                      SELECT\n",
    "                          `AVERAGE AIR TIME (IN RAW MINUTES)`,\n",
    "                          CONCAT (FLOOR (`AVERAGE AIR TIME (IN RAW MINUTES)` / 60), \" HOURS\") AS `AVERAGE AIR TIME (IN HOURS)`,\n",
    "                          CONCAT (ROUND (MOD (`AVERAGE AIR TIME (IN RAW MINUTES)`, 60), 0), \" MINUTES\") AS `AVERAGE AIR TIME (IN MINUTES)`,\n",
    "                          CONCAT\n",
    "                              (FLOOR (`AVERAGE AIR TIME (IN RAW MINUTES)` / 60), \" HOURS \",\n",
    "                              ROUND (MOD (`AVERAGE AIR TIME (IN RAW MINUTES)`, 60), 0), \" MINUTES\")\n",
    "                                                                                        AS `AVERAGE AIR TIME`\n",
    "                      FROM\n",
    "                          AVERAGE_AIRTIME_CTE\n",
    "                   \"\"\"\n",
    "\n",
    "    return spark.sql(sql_query_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64f1997a-8eff-456b-9968-33161da47328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Average Airtime for flights that left before 9:00 AM is as follows:-\n",
      "\n",
      "+---------------------------------+---------------------------+-----------------------------+--------------------+\n",
      "|AVERAGE AIR TIME (IN RAW MINUTES)|AVERAGE AIR TIME (IN HOURS)|AVERAGE AIR TIME (IN MINUTES)|    AVERAGE AIR TIME|\n",
      "+---------------------------------+---------------------------+-----------------------------+--------------------+\n",
      "|                           111.36|                    1 HOURS|                 51.0 MINUTES|1 HOURS 51.0 MINUTES|\n",
      "+---------------------------------+---------------------------+-----------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"The Average Airtime for flights that left before 9:00 AM is as follows:-\\n\")\n",
    "average_air_time(domestic_flight_df).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41a3da-eba9-4791-8e66-bc84a4061b43",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e1497f-329b-42f8-bfb4-bc4453e2c9b6",
   "metadata": {},
   "source": [
    "#### Maximum Arrival Delay for Flights With No Departure Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "239f7d43-efd7-4576-a28d-58ed4e9f071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_arrival_delay(dataframe):\n",
    "    \"\"\"\n",
    "    Docstring: \n",
    "               Take's a PySpark Dataframe as input.\n",
    "               Determins the Maximum Arrival Delay for flights that did not experience a delay upon departure.\n",
    "               Return a PySpark Dataframe with the Maximum Arrival Delay for flights that did not experience a delay upon departure.\n",
    "    Parameters: \n",
    "               Spark DataFrame\n",
    "    Arguments: \n",
    "               Domestic Flights PySpark DataFrame\n",
    "    Returns:\n",
    "               A PySpark Dataframe with the Maximum Arrival Delay for flights that did not experience a delay upon departure.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a Temporary View for SQL Query\n",
    "    dataframe.createOrReplaceTempView(\"domestic_flight_view\")\n",
    "\n",
    "    sql_query_1 = f\"\"\"\n",
    "                      WITH MAXIMUM_ARRIVAL_DELAY_CTE AS\n",
    "                      (SELECT \n",
    "                          MAX(ARR_DELAY) AS `MAXIMUM DELAY (IN RAW MINUTES)`\n",
    "                      FROM\n",
    "                          domestic_flight_view\n",
    "                      WHERE\n",
    "                          DEP_DELAY <= 0)\n",
    "                          \n",
    "                      SELECT\n",
    "                          `MAXIMUM DELAY (IN RAW MINUTES)`,\n",
    "                          CONCAT (FLOOR (`MAXIMUM DELAY (IN RAW MINUTES)` / 60), ' HOURS') AS `MAXIMUM DELAY (IN HOURS)`,\n",
    "                          CONCAT (ROUND (MOD (`MAXIMUM DELAY (IN RAW MINUTES)`, 60), 0), ' MINUTES') AS `MAXIMUM DELAY (IN MINUTES)`,\n",
    "                          CONCAT\n",
    "                              (FLOOR (`MAXIMUM DELAY (IN RAW MINUTES)` / 60), ' HOURS ',\n",
    "                              ROUND (MOD (`MAXIMUM DELAY (IN RAW MINUTES)`, 60), 0), ' MINUTES')\n",
    "                                                                                        AS `MAXIMUM DELAY`\n",
    "                      FROM\n",
    "                          MAXIMUM_ARRIVAL_DELAY_CTE \n",
    "                   \"\"\"\n",
    "\n",
    "    return spark.sql(sql_query_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73470c79-90e5-4ca4-9699-5560e8b0a051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Maximum Arrival Delay for flights that did not experience a delay upon departure is:-\n",
      "\n",
      "+------------------------------+------------------------+--------------------------+-------------------+\n",
      "|MAXIMUM DELAY (IN RAW MINUTES)|MAXIMUM DELAY (IN HOURS)|MAXIMUM DELAY (IN MINUTES)|      MAXIMUM DELAY|\n",
      "+------------------------------+------------------------+--------------------------+-------------------+\n",
      "|                           701|                11 HOURS|                41 MINUTES|11 HOURS 41 MINUTES|\n",
      "+------------------------------+------------------------+--------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"The Maximum Arrival Delay for flights that did not experience a delay upon departure is:-\\n\")\n",
    "maximum_arrival_delay(domestic_flight_df).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e69b1-542f-4b46-8019-a44e5952eb16",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaaa319-a9a1-45fe-91f3-0530f84339d4",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "- **`5,34,653`** Flights arrived earlier than expected. **`53.47%`** percentage of early arrivals.\n",
    "- The typical departure time for flights over 2000 miles is **`1:58 PM (Noon)`**.\n",
    "- The Proportion of Flights with Delay longer than 60 minutues : **`5.31 %`**\n",
    "- The average airtime for flights that left earlier than 9:00 am : **`1 HOUR 51.0 MINUTES`**\n",
    "- The Maximum Arrival Delay for flights that did not experience a delay upon departure : **`11 HOURS 41 MINUTES`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752921e-25df-427a-aee3-5adecb931c1c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a403cb07-78b5-4cb5-9405-91a0eec137af",
   "metadata": {},
   "source": [
    "### Author : Russel Anthony Reynold Chandanshiv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6c2b9f-ee58-465e-8516-564fbf811e20",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
